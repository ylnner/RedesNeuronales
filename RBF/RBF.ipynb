{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from MLPClass import MLPClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(data):\n",
    "    label_target = data[0]\n",
    "    target = []\n",
    "    \n",
    "    for i in range(len(label_target)):\n",
    "        if label_target[i] == 1:\n",
    "            element = [1, 0, 0]\n",
    "        elif label_target[i] == 2:\n",
    "            element = [0, 1, 0]\n",
    "        elif label_target[i] == 3:\n",
    "            element = [0, 0, 1]\n",
    "        target.append(element)\n",
    "    \n",
    "    x_without_target = data.drop([0], axis = 1)\n",
    "    temp             = x_without_target.values.astype(float)\n",
    "    min_max_scaler   = preprocessing.MinMaxScaler()\n",
    "    x_scaled         = min_max_scaler.fit_transform(temp)\n",
    "    predictive       = pd.DataFrame(x_scaled)\n",
    "    \n",
    "    return np.array(predictive), np.array(target), (label_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Centers(predictive, label_target):\n",
    "    old_value = label_target[0]\n",
    "    old_idx = 0\n",
    "    centers_dataset = []\n",
    "    groups = []\n",
    "    \n",
    "    for idx, value in label_target.items():\n",
    "        \n",
    "        if old_value != value or idx == len(label_target) - 1:\n",
    "            new_df = predictive.iloc[old_idx:idx]\n",
    "            centers_dataset.append(new_df.mean(axis = 0))\n",
    "            old_idx   = idx\n",
    "            old_value = value\n",
    "            groups.append(new_df)\n",
    "            \n",
    "    centers_dataset = np.array(centers_dataset)\n",
    "    return centers_dataset, groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMiniBatches(x, y, size): \n",
    "    mini_batches  = []    \n",
    "    try:\n",
    "        aux = y.shape[1]        \n",
    "    except:\n",
    "        aux = 1        \n",
    "\n",
    "    data          = np.hstack((x, np.array(y).reshape(y.shape[0], aux)))    \n",
    "    n_minibatches = data.shape[0] // size \n",
    "    i             = 0\n",
    "    \n",
    "    np.random.shuffle(data) # Random data\n",
    "    for i in range(n_minibatches + 1):\n",
    "        mb     = np.array(data[i * size:(i + 1)*size, :])         \n",
    "        x_mini = mb[:, :-aux]\n",
    "        y_mini = mb[:, x.shape[1]:].reshape((-aux, aux))    \n",
    "        mini_batches.append((x_mini, y_mini)) \n",
    "\n",
    "    if data.shape[0] % size != 0: # If there needs to create one adittional mini batch\n",
    "        mb     = data[i * size:data.shape[0]] \n",
    "        x_mini = mb[:, :-aux] \n",
    "        y_mini = mb[:, x.shape[1]:].reshape((-aux, aux))\n",
    "        mini_batches.append((x_mini, y_mini))\n",
    "\n",
    "    return np.array(mini_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vj = ||x - cj|| -----------  v = [v1,...,vj]\n",
    "# x: vetor de entrada\n",
    "# c: centro da função radial  (miu)\n",
    "# s: largura da função radial (sigma)\n",
    "\n",
    "# Others functions:\n",
    "def closest(x,vectors):\n",
    "    distance = []\n",
    "    for i in range(len(vectors)):\n",
    "        distance.append(np.linalg.norm(np.array(x)-np.array(vectors[i])))\n",
    "    index = distance.index(min(distance))\n",
    "    return vectors[index]\n",
    "\n",
    "def flatten(Matrix, axis):\n",
    "    F1 = Matrix[0]\n",
    "    for i in range(len(Matrix)-1):\n",
    "        F2 = Matrix[i+1]\n",
    "        if (axis==1):\n",
    "            Flat = np.concatenate((F1, F2), axis=1)\n",
    "        else:\n",
    "            Flat = np.concatenate((F1, F2), axis=0)\n",
    "        F1 = Flat        \n",
    "    return Flat\n",
    "\n",
    "# Definition of widths:\n",
    "# Heuristic 1: s = 1/m * somatorio(i=1,m)||ci-c|| -----> c centro mas cercano a ci \n",
    "def heuristic_1(centers):\n",
    "    sj = []\n",
    "    for j in range(len(centers)):\n",
    "            x = centers[0]\n",
    "            centers.remove(x)\n",
    "            y = closest(x, centers)  # centro mas cercano al centro actual x\n",
    "            sj.append(np.linalg.norm(np.array(x)-np.array(y)))\n",
    "            centers.append(x)\n",
    "    return (np.ones([1,3])*(float(1/len(centers))*np.sum(sj)))      \n",
    "\n",
    "# Heuristic 2: si = alpha * ||ci-c||   -----> 1<alpha<1.5 c centro mas cercano al centro ci \n",
    "def heuristic_2(alpha,centers):\n",
    "    s = []\n",
    "    for i in range(len(centers)):\n",
    "        x = centers[0]\n",
    "        centers.remove(x)\n",
    "        y = closest(x, centers)  # centro mas cercano al centro actual x\n",
    "        s.append(alpha*np.linalg.norm(np.array(x)-np.array(y)))\n",
    "        centers.append(x)\n",
    "    return np.array(s)\n",
    "\n",
    "# heuristic 3: si = distância média de seu centro aos N vetores de entrada mais próximos\n",
    "def heuristic_3(N,centers,groups):\n",
    "    # N<=47\n",
    "    s = []\n",
    "    for i in range(len(centers)):\n",
    "        center_current = centers[i]\n",
    "        group_current = np.array(groups[i])\n",
    "        sj = []\n",
    "        for j in range(N):\n",
    "            sj.append(np.linalg.norm(group_current[j]-np.array(center_current)))\n",
    "        s.append(float(1/N)*np.sum(sj))\n",
    "    return s\n",
    "\n",
    "# heuristic 4:  # si = valor constante (geralmente 1)\n",
    "def heuristic_4(): \n",
    "    return(np.ones([1,3]))\n",
    "\n",
    "def sigma_heuristics(centers, groups, N, alpha, option = 1):\n",
    "    if option==1:\n",
    "        sigma = heuristic_1(centers)\n",
    "    elif option==2:\n",
    "        sigma = heuristic_2(alpha, centers)\n",
    "    elif option==3:\n",
    "        sigma = heuristic_3(N, centers, groups)\n",
    "    else:\n",
    "        sigma = heuristic_4()\n",
    "    return sigma \n",
    "        \n",
    "# Activations functions:\n",
    "def sigmoid(x):\n",
    "    return (1 /(1+ np.exp(-x)))\n",
    "\n",
    "# Radial functions:\n",
    "def Gaussian(v,sigma): \n",
    "    # phi(v) = exp(-(v^2)/ 2*sigma^2)\n",
    "    return (np.exp(-(v**2)/ 2*(sigma**2)))\n",
    "\n",
    "def Multiquadratic(v,sigma):\n",
    "    # phi(v) = raiz(v^2 + sigma^2)\n",
    "    return (np.sqrt(v**2 + sigma**2))\n",
    "\n",
    "def Thin_Plate_Spline(v):\n",
    "    # phi(v) = v^2 * log(v)\n",
    "    return (v**2 * np.log(v))\n",
    "\n",
    "def phi(x, center, sigma, function):\n",
    "    v = np.linalg.norm((np.subtract(x,center)))\n",
    "    if function =='Gaussian':\n",
    "        phi = Gaussian(v,sigma)\n",
    "    elif function =='Multiquadratic':\n",
    "        phi = Multiquadratic(v,sigma)\n",
    "    elif function =='Thin_Plate_Spline':\n",
    "        phi = Thin_Plate_Spline(v)\n",
    "    return phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data, target, old_target = []):\n",
    "    stratSplit = StratifiedShuffleSplit(n_splits=1, test_size=0.8, random_state=42)\n",
    "    for test_idx, train_idx in stratSplit.split(data, target):\n",
    "        data_train   = data[train_idx]\n",
    "        target_train = target[train_idx]\n",
    "\n",
    "        data_test = data[test_idx]\n",
    "        target_test = target[test_idx]\n",
    "        \n",
    "        old_target_test = old_target[test_idx]\n",
    "        old_target_train = old_target[train_idx]\n",
    "        return np.array(data_train), np.array(data_test), np.array(target_train), np.array(target_test), np.array(old_target_test), np.array(old_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_RBF(Input, centers, W, number_neurons, sigma, function):\n",
    "    phi_values = []\n",
    "    for i in range(len(centers)):\n",
    "        phi_values.append(phi(Input, centers[i], sigma[0][i], function))\n",
    "    phi_values.append(1)# Adding bias\n",
    "    phi_values = np.array(phi_values)\n",
    "    output = sigmoid(np.dot(phi_values, np.transpose(np.matrix(W)))) \n",
    "    return output, phi_values    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def heuristic_1(centers, groups):\n",
    "#     sj     = []\n",
    "#     for i in range(len(groups)):\n",
    "#         group_current = groups[0]\n",
    "#         center_current = centers[0]\n",
    "#         groups.remove(group_current)\n",
    "#         centers.remove(center_current)\n",
    "#         Groups = []\n",
    "#         for k in range(len(groups)):\n",
    "#             Groups.append(np.array(groups[k]))\n",
    "#         Groups = flatten(Groups, axis = 0) \n",
    "#         for j in range(len(group_current)):\n",
    "#             point_closest = closest(group_current[j], Groups)\n",
    "#             if (point_closest in np.array(groups[0])):\n",
    "#                 sj.append(np.linalg.norm(np.array(center_current)-np.array(centers[0])))\n",
    "#             elif (point_closest in groups[1]):\n",
    "#                 sj.append(np.linalg.norm(np.array(center_current)-np.array(centers[1])))       \n",
    "#         groups.append(group_current)  \n",
    "#         centers.append(center_current)\n",
    "#     return (np.ones([1,3])*(float(1/177)*np.sum(sj)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"wine.data\", header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing Data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive, target, label_target = Preprocessing(data)\n",
    "centers_dataset, groups = Centers(pd.DataFrame(predictive), label_target)\n",
    "data_train, data_test, target_train, target_test, old_target_test, old_target_train = split_dataset(predictive, target, label_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining General Parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeMiniBatch = 1\n",
    "lowWeight     = -1\n",
    "highWeight    = 1\n",
    "learningRate  = 0.002\n",
    "alphaMomentum = 0\n",
    "maxNumberOfIterations = 115"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing MLP..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on iteration 50: 0.4\n",
      "Accuracy on iteration 100: 0.4\n",
      "Accuracy on iteration 115: 0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "mini_batches  = getMiniBatches(data_train, target_train, sizeMiniBatch)\n",
    "size_x        = len(mini_batches[0][0][0])\n",
    "size_y        = 3\n",
    "w_middle      = []\n",
    "w_output      = []\n",
    "wb_middle     = []\n",
    "wb_output     = []\n",
    "\n",
    "\n",
    "neuronsOnHiddenLayer = [3]\n",
    "MLPClassifier        = MLPClass(lowWeight, highWeight, neuronsOnHiddenLayer, size_x, size_y)\n",
    "\n",
    "for epoch in range(maxNumberOfIterations):\n",
    "    nb = 0\n",
    "    for mb in mini_batches:\n",
    "        # print('Numero Batch: ', nb)\n",
    "        if len(mb[0]) != 0:\t# Checks that mini batch has data\n",
    "            x_mini = mb[0]\n",
    "            y_mini = mb[1]\n",
    "\n",
    "            w_middle, w_output, wb_middle, wb_output = MLPClassifier.fit_by_mini_batch(x_mini, y_mini, learningRate, alphaMomentum)\n",
    "        nb = nb + 1\n",
    "    errorGlobal = 0\n",
    "    y_pred = []\n",
    "    for i in range(len(data_test)):\n",
    "        y_layer, y_net, error = MLPClassifier.forward(data_test[i], target_test[i], w_middle, w_output, wb_middle, wb_output)\n",
    "        result = np.where(y_net == np.amax(y_net))\n",
    "        y_pred.append(result[0][0] + 1)\n",
    "        errorGlobal = errorGlobal + error\n",
    "\n",
    "    errorGlobal = errorGlobal / len(data_test)\n",
    "    if (epoch + 1) % 50 == 0 or epoch == maxNumberOfIterations - 1:\n",
    "        print('Accuracy on iteration ' + str(epoch + 1) + ': ' + str(accuracy_score(np.array(old_target_test),np.array(y_pred))))\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing RBF..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on iteration 50: 0.4\n",
      "Accuracy on iteration 100: 0.6571428571428571\n",
      "Accuracy on iteration 115: 0.7714285714285715\n"
     ]
    }
   ],
   "source": [
    "centers = centers_dataset\n",
    "number_neurons = 3\n",
    "W        = np.random.uniform(low = -1, high = 1, size = [number_neurons, len(centers)+1])\n",
    "function = 'Gaussian'\n",
    "N = 40 # N<=47\n",
    "alpha = 1\n",
    "sigma = sigma_heuristics(list(centers), groups, N, alpha, option = 1)\n",
    "\n",
    "\n",
    "for n in range(maxNumberOfIterations):\n",
    "    for i in range(len(data_train)):\n",
    "        output, phi_values = forward_RBF(data_train[i], centers, W, number_neurons, sigma, function)\n",
    "        aux = learning_rate * np.multiply(np.transpose(np.matrix(target_train[i] - output)), np.array(phi_values))\n",
    "        W = W + aux\n",
    "    \n",
    "    if (n + 1) %50 == 0 or n == maxNumberOfIterations -1:\n",
    "        y_pred = []\n",
    "        for i in range(len(data_test)):\n",
    "            output, phi_values = forward_RBF(data_test[i], centers, W, number_neurons, sigma, function)\n",
    "            result = np.where(output == np.amax(output))\n",
    "            a = np.argmax(output)\n",
    "            y_pred.append(a + 1)\n",
    "        print('Accuracy on iteration ' + str(n+1) +': '+ str(accuracy_score(np.array(old_target_test),np.array(y_pred))))\n",
    "\n",
    "        \n",
    "# print('W: ', W)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

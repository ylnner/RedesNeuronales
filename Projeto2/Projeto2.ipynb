{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(categories):\n",
    "    # Training and Testing\n",
    "    data             = []\n",
    "    target           = []\n",
    "    size_image       = 48\n",
    "    img_dir          = 'train'    \n",
    "    \n",
    "    for idx, category in enumerate(categories):\n",
    "        img_dir_aux = img_dir + '/'+ category\n",
    "        data_path   = os.path.join(img_dir_aux, '*g')\n",
    "        files       = glob.glob(data_path)\n",
    "        for f1 in files:\n",
    "            img        = cv2.imread(f1)\n",
    "            img_resize = cv2.resize(img, (size_image, size_image), interpolation = cv2.INTER_AREA)\n",
    "            data.append(img_resize)\n",
    "            target.append(idx)\n",
    "    \n",
    "    \n",
    "\n",
    "    target     = keras.utils.to_categorical(target, len(categories))    \n",
    "    data       = np.array(data)\n",
    "    target     = np.array(target)\n",
    "    \n",
    "    data =data.astype(np.uint8)/255.0 \n",
    "    \n",
    "    \n",
    "    stratSplit = StratifiedShuffleSplit(n_splits=1, test_size=0.8, random_state=42)\n",
    "    for test_idx, train_idx in stratSplit.split(data, target):        \n",
    "        train_data   = data[train_idx]\n",
    "        train_target = target[train_idx]                        \n",
    "        test_data    = data[test_idx]\n",
    "        test_target  = target[test_idx]\n",
    "        \n",
    "    # Validation\n",
    "    val_data   = []\n",
    "    val_target = []\n",
    "    img_dir    = 'val'\n",
    "    for idx, category in enumerate(categories):        \n",
    "        img_dir_aux = img_dir + '/'+ category\n",
    "        data_path   = os.path.join(img_dir_aux, '*g')\n",
    "        files       = glob.glob(data_path)        \n",
    "        for f1 in files:\n",
    "            img        = cv2.imread(f1)\n",
    "            img_resize = cv2.resize(img, (size_image, size_image), interpolation = cv2.INTER_AREA)\n",
    "            val_data.append(img_resize)\n",
    "            val_target.append(idx)\n",
    "    \n",
    "    val_target   = keras.utils.to_categorical(val_target, len(categories))                \n",
    "    val_data     = np.array(val_data)\n",
    "    \n",
    "    val_data =val_data.astype(np.uint8)/255.0\n",
    "    \n",
    "    val_target   = np.array(val_target)\n",
    "    \n",
    "    np.random.shuffle(val_data)\n",
    "    np.random.shuffle(val_target)    \n",
    "    \n",
    "    return train_data, train_target, test_data, test_target, val_data, val_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size        = 32\n",
    "num_classes       = 7\n",
    "save_dir          = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name        = 'faces.h5'\n",
    "categories  = ['angry','disgust','fear','happy','neutral','sad','surprise']\n",
    "train_data, train_target, test_data, test_target, val_data, val_target = load_data(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs            = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 48, 48, 3)\n",
      "Train on 2328 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "2328/2328 [==============================] - 50s 22ms/step - loss: 4.0147 - acc: 0.1731 - val_loss: 2.1606 - val_acc: 0.1380\n",
      "Epoch 2/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 2.6194 - acc: 0.1783 - val_loss: 1.9096 - val_acc: 0.2370\n",
      "Epoch 3/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 2.1988 - acc: 0.1821 - val_loss: 1.8671 - val_acc: 0.4010\n",
      "Epoch 4/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 2.0300 - acc: 0.1980 - val_loss: 1.8700 - val_acc: 0.4660\n",
      "Epoch 5/100\n",
      "2328/2328 [==============================] - 45s 19ms/step - loss: 1.9599 - acc: 0.2083 - val_loss: 1.8045 - val_acc: 0.4640\n",
      "Epoch 6/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.9371 - acc: 0.2212 - val_loss: 1.8574 - val_acc: 0.4650\n",
      "Epoch 7/100\n",
      "2328/2328 [==============================] - 45s 19ms/step - loss: 1.9254 - acc: 0.2131 - val_loss: 1.8261 - val_acc: 0.4650\n",
      "Epoch 8/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.9222 - acc: 0.2350 - val_loss: 1.8150 - val_acc: 0.4650\n",
      "Epoch 9/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.9064 - acc: 0.2405 - val_loss: 1.8092 - val_acc: 0.4650\n",
      "Epoch 10/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.8812 - acc: 0.2440 - val_loss: 1.7928 - val_acc: 0.4650\n",
      "Epoch 11/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.8737 - acc: 0.2500 - val_loss: 1.7881 - val_acc: 0.4650\n",
      "Epoch 12/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.8682 - acc: 0.2474 - val_loss: 1.7228 - val_acc: 0.4650\n",
      "Epoch 13/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.8533 - acc: 0.2590 - val_loss: 1.7732 - val_acc: 0.4650\n",
      "Epoch 14/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.8512 - acc: 0.2491 - val_loss: 1.7623 - val_acc: 0.4650\n",
      "Epoch 15/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.8391 - acc: 0.2539 - val_loss: 1.7971 - val_acc: 0.4650\n",
      "Epoch 16/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.8291 - acc: 0.2504 - val_loss: 1.7909 - val_acc: 0.4650\n",
      "Epoch 17/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.7875 - acc: 0.2659 - val_loss: 1.7495 - val_acc: 0.4640\n",
      "Epoch 18/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.7867 - acc: 0.2650 - val_loss: 1.8145 - val_acc: 0.4650\n",
      "Epoch 19/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.7754 - acc: 0.2702 - val_loss: 1.8393 - val_acc: 0.4310\n",
      "Epoch 20/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.7252 - acc: 0.2848 - val_loss: 1.8246 - val_acc: 0.4500\n",
      "Epoch 21/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.6937 - acc: 0.3003 - val_loss: 2.0837 - val_acc: 0.4440\n",
      "Epoch 22/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.6779 - acc: 0.3273 - val_loss: 2.0678 - val_acc: 0.2060\n",
      "Epoch 23/100\n",
      "2328/2328 [==============================] - 45s 19ms/step - loss: 1.6547 - acc: 0.3415 - val_loss: 2.2974 - val_acc: 0.3690\n",
      "Epoch 24/100\n",
      "2328/2328 [==============================] - 45s 19ms/step - loss: 1.6311 - acc: 0.3424 - val_loss: 2.2227 - val_acc: 0.3520\n",
      "Epoch 25/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.5953 - acc: 0.3647 - val_loss: 2.3169 - val_acc: 0.1680\n",
      "Epoch 26/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.5899 - acc: 0.3625 - val_loss: 2.2279 - val_acc: 0.2360\n",
      "Epoch 27/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.5845 - acc: 0.3750 - val_loss: 2.3384 - val_acc: 0.2300\n",
      "Epoch 28/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.5525 - acc: 0.3806 - val_loss: 2.3549 - val_acc: 0.1550\n",
      "Epoch 29/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.5220 - acc: 0.3793 - val_loss: 2.4853 - val_acc: 0.2710\n",
      "Epoch 30/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.5105 - acc: 0.3939 - val_loss: 3.7679 - val_acc: 0.4190\n",
      "Epoch 31/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.5033 - acc: 0.4107 - val_loss: 2.9975 - val_acc: 0.2280\n",
      "Epoch 32/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.5129 - acc: 0.4076 - val_loss: 2.4124 - val_acc: 0.3160\n",
      "Epoch 33/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.4751 - acc: 0.3999 - val_loss: 2.8684 - val_acc: 0.1850\n",
      "Epoch 34/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.4606 - acc: 0.4223 - val_loss: 2.5817 - val_acc: 0.2740\n",
      "Epoch 35/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.4379 - acc: 0.4192 - val_loss: 3.2015 - val_acc: 0.2600\n",
      "Epoch 36/100\n",
      "2328/2328 [==============================] - 45s 19ms/step - loss: 1.4145 - acc: 0.4424 - val_loss: 3.0893 - val_acc: 0.2660\n",
      "Epoch 37/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.3896 - acc: 0.4476 - val_loss: 3.7395 - val_acc: 0.2500\n",
      "Epoch 38/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.3957 - acc: 0.4562 - val_loss: 3.2203 - val_acc: 0.2370\n",
      "Epoch 39/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.3848 - acc: 0.4583 - val_loss: 3.6967 - val_acc: 0.2650\n",
      "Epoch 40/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.3805 - acc: 0.4686 - val_loss: 3.8415 - val_acc: 0.2940\n",
      "Epoch 41/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.3564 - acc: 0.4742 - val_loss: 3.8897 - val_acc: 0.3200\n",
      "Epoch 42/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.3276 - acc: 0.4802 - val_loss: 3.7641 - val_acc: 0.2530\n",
      "Epoch 43/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.3028 - acc: 0.4940 - val_loss: 3.4709 - val_acc: 0.2380\n",
      "Epoch 44/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.3078 - acc: 0.4948 - val_loss: 2.5062 - val_acc: 0.2380\n",
      "Epoch 45/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.3338 - acc: 0.4738 - val_loss: 3.8933 - val_acc: 0.2530\n",
      "Epoch 46/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.2548 - acc: 0.5043 - val_loss: 3.5703 - val_acc: 0.2050\n",
      "Epoch 47/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.2806 - acc: 0.5073 - val_loss: 3.8323 - val_acc: 0.2350\n",
      "Epoch 48/100\n",
      "2328/2328 [==============================] - 44s 19ms/step - loss: 1.2370 - acc: 0.5103 - val_loss: 4.3575 - val_acc: 0.1540\n",
      "Epoch 49/100\n",
      "2328/2328 [==============================] - 45s 19ms/step - loss: 1.2322 - acc: 0.5198 - val_loss: 3.5284 - val_acc: 0.2390\n",
      "Epoch 50/100\n",
      "2328/2328 [==============================] - 45s 20ms/step - loss: 1.2146 - acc: 0.5292 - val_loss: 4.7092 - val_acc: 0.2910\n",
      "Epoch 51/100\n",
      "2328/2328 [==============================] - 45s 19ms/step - loss: 1.1943 - acc: 0.5301 - val_loss: 3.8603 - val_acc: 0.2530\n",
      "Epoch 52/100\n",
      "2328/2328 [==============================] - 48s 21ms/step - loss: 1.1517 - acc: 0.5395 - val_loss: 3.1208 - val_acc: 0.2660\n",
      "Epoch 53/100\n",
      "2328/2328 [==============================] - 52s 22ms/step - loss: 1.1598 - acc: 0.5537 - val_loss: 3.7448 - val_acc: 0.2560\n",
      "Epoch 54/100\n",
      "2328/2328 [==============================] - 55s 24ms/step - loss: 1.1513 - acc: 0.5485 - val_loss: 4.2014 - val_acc: 0.3410\n",
      "Epoch 55/100\n",
      "2328/2328 [==============================] - 51s 22ms/step - loss: 1.1086 - acc: 0.5679 - val_loss: 3.9914 - val_acc: 0.2480\n",
      "Epoch 56/100\n",
      "2328/2328 [==============================] - 54s 23ms/step - loss: 1.1223 - acc: 0.5597 - val_loss: 4.0781 - val_acc: 0.2290\n",
      "Epoch 57/100\n",
      "2328/2328 [==============================] - 51s 22ms/step - loss: 1.0653 - acc: 0.5752 - val_loss: 4.8381 - val_acc: 0.2960\n",
      "Epoch 58/100\n",
      "2328/2328 [==============================] - 53s 23ms/step - loss: 1.0487 - acc: 0.5859 - val_loss: 4.7353 - val_acc: 0.2380\n",
      "Epoch 59/100\n",
      "2328/2328 [==============================] - 51s 22ms/step - loss: 1.0435 - acc: 0.5820 - val_loss: 4.2585 - val_acc: 0.2570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "2328/2328 [==============================] - 48s 21ms/step - loss: 1.0599 - acc: 0.5790 - val_loss: 4.3746 - val_acc: 0.2620\n",
      "Epoch 61/100\n",
      "2328/2328 [==============================] - 56s 24ms/step - loss: 0.9862 - acc: 0.5919 - val_loss: 4.9120 - val_acc: 0.2780\n",
      "Epoch 62/100\n",
      "2328/2328 [==============================] - 50s 21ms/step - loss: 0.9812 - acc: 0.6138 - val_loss: 4.2295 - val_acc: 0.2340\n",
      "Epoch 63/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 0.9671 - acc: 0.6001 - val_loss: 4.0973 - val_acc: 0.2250\n",
      "Epoch 64/100\n",
      "2328/2328 [==============================] - 50s 21ms/step - loss: 0.9505 - acc: 0.6057 - val_loss: 5.1668 - val_acc: 0.3050\n",
      "Epoch 65/100\n",
      "2328/2328 [==============================] - 54s 23ms/step - loss: 0.9348 - acc: 0.6211 - val_loss: 4.8592 - val_acc: 0.2300\n",
      "Epoch 66/100\n",
      "2328/2328 [==============================] - 56s 24ms/step - loss: 0.9716 - acc: 0.5975 - val_loss: 5.2829 - val_acc: 0.2570\n",
      "Epoch 67/100\n",
      "2328/2328 [==============================] - 47s 20ms/step - loss: 0.8988 - acc: 0.6186 - val_loss: 4.9512 - val_acc: 0.2250\n",
      "Epoch 68/100\n",
      "2328/2328 [==============================] - 50s 21ms/step - loss: 0.9096 - acc: 0.6254 - val_loss: 4.7942 - val_acc: 0.2300\n",
      "Epoch 69/100\n",
      "2328/2328 [==============================] - 72s 31ms/step - loss: 0.9109 - acc: 0.6250 - val_loss: 5.0080 - val_acc: 0.2480\n",
      "Epoch 70/100\n",
      "2328/2328 [==============================] - 55s 24ms/step - loss: 0.8480 - acc: 0.6336 - val_loss: 5.2078 - val_acc: 0.2190\n",
      "Epoch 71/100\n",
      "2328/2328 [==============================] - 51s 22ms/step - loss: 0.8787 - acc: 0.6349 - val_loss: 4.6343 - val_acc: 0.2480\n",
      "Epoch 72/100\n",
      "2328/2328 [==============================] - 50s 22ms/step - loss: 0.8667 - acc: 0.6203 - val_loss: 5.2186 - val_acc: 0.2210\n",
      "Epoch 73/100\n",
      "2328/2328 [==============================] - 50s 22ms/step - loss: 0.8342 - acc: 0.6362 - val_loss: 5.0837 - val_acc: 0.2360\n",
      "Epoch 74/100\n",
      "2328/2328 [==============================] - 47s 20ms/step - loss: 0.8179 - acc: 0.6568 - val_loss: 4.5372 - val_acc: 0.2260\n",
      "Epoch 75/100\n",
      "2328/2328 [==============================] - 52s 22ms/step - loss: 0.8324 - acc: 0.6469 - val_loss: 4.7229 - val_acc: 0.2230\n",
      "Epoch 76/100\n",
      "2328/2328 [==============================] - 50s 22ms/step - loss: 0.8121 - acc: 0.6594 - val_loss: 4.7629 - val_acc: 0.2250\n",
      "Epoch 77/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 0.8153 - acc: 0.6229 - val_loss: 5.3190 - val_acc: 0.2400\n",
      "Epoch 78/100\n",
      "2328/2328 [==============================] - 50s 22ms/step - loss: 0.7683 - acc: 0.6654 - val_loss: 5.3908 - val_acc: 0.2400\n",
      "Epoch 79/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 0.8008 - acc: 0.6796 - val_loss: 4.9898 - val_acc: 0.2310\n",
      "Epoch 80/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 0.7858 - acc: 0.6572 - val_loss: 5.0620 - val_acc: 0.2290\n",
      "Epoch 81/100\n",
      "2328/2328 [==============================] - 57s 25ms/step - loss: 0.7350 - acc: 0.6886 - val_loss: 5.5220 - val_acc: 0.2400\n",
      "Epoch 82/100\n",
      "2328/2328 [==============================] - 51s 22ms/step - loss: 0.7550 - acc: 0.6860 - val_loss: 4.9977 - val_acc: 0.2230\n",
      "Epoch 83/100\n",
      "2328/2328 [==============================] - 56s 24ms/step - loss: 0.7477 - acc: 0.6821 - val_loss: 6.4771 - val_acc: 0.2680\n",
      "Epoch 84/100\n",
      "2328/2328 [==============================] - 53s 23ms/step - loss: 0.7667 - acc: 0.6830 - val_loss: 4.8749 - val_acc: 0.2200\n",
      "Epoch 85/100\n",
      "2328/2328 [==============================] - 52s 22ms/step - loss: 0.7246 - acc: 0.6993 - val_loss: 5.7294 - val_acc: 0.2450\n",
      "Epoch 86/100\n",
      "2328/2328 [==============================] - 52s 22ms/step - loss: 0.6998 - acc: 0.6993 - val_loss: 5.7982 - val_acc: 0.2260\n",
      "Epoch 87/100\n",
      "2328/2328 [==============================] - 58s 25ms/step - loss: 0.6907 - acc: 0.7019 - val_loss: 5.4807 - val_acc: 0.1880\n",
      "Epoch 88/100\n",
      "2328/2328 [==============================] - 54s 23ms/step - loss: 0.7009 - acc: 0.7062 - val_loss: 5.8541 - val_acc: 0.2390\n",
      "Epoch 89/100\n",
      "2328/2328 [==============================] - 53s 23ms/step - loss: 0.6706 - acc: 0.7229 - val_loss: 6.0564 - val_acc: 0.2380\n",
      "Epoch 90/100\n",
      "2328/2328 [==============================] - 52s 22ms/step - loss: 0.6676 - acc: 0.7298 - val_loss: 6.2561 - val_acc: 0.2270\n",
      "Epoch 91/100\n",
      "2328/2328 [==============================] - 51s 22ms/step - loss: 0.6569 - acc: 0.7259 - val_loss: 6.1376 - val_acc: 0.2270\n",
      "Epoch 92/100\n",
      "2328/2328 [==============================] - 51s 22ms/step - loss: 0.6755 - acc: 0.7247 - val_loss: 5.6611 - val_acc: 0.2380\n",
      "Epoch 93/100\n",
      "2328/2328 [==============================] - 52s 22ms/step - loss: 0.6365 - acc: 0.7298 - val_loss: 6.2508 - val_acc: 0.2330\n",
      "Epoch 94/100\n",
      "2328/2328 [==============================] - 55s 24ms/step - loss: 0.6324 - acc: 0.7440 - val_loss: 5.0796 - val_acc: 0.1900\n",
      "Epoch 95/100\n",
      "2328/2328 [==============================] - 54s 23ms/step - loss: 0.6444 - acc: 0.7547 - val_loss: 5.9107 - val_acc: 0.2140\n",
      "Epoch 96/100\n",
      "2328/2328 [==============================] - 58s 25ms/step - loss: 0.6351 - acc: 0.7509 - val_loss: 5.8079 - val_acc: 0.1980\n",
      "Epoch 97/100\n",
      "2328/2328 [==============================] - 59s 25ms/step - loss: 0.5782 - acc: 0.7590 - val_loss: 6.5780 - val_acc: 0.2200\n",
      "Epoch 98/100\n",
      "2328/2328 [==============================] - 53s 23ms/step - loss: 0.5069 - acc: 0.7835 - val_loss: 6.5610 - val_acc: 0.2280\n",
      "Epoch 99/100\n",
      "2328/2328 [==============================] - 55s 23ms/step - loss: 0.5817 - acc: 0.7736 - val_loss: 6.1817 - val_acc: 0.2060\n",
      "Epoch 100/100\n",
      "2328/2328 [==============================] - 52s 22ms/step - loss: 0.5554 - acc: 0.7762 - val_loss: 7.1365 - val_acc: 0.2230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa571f05bd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation = 'relu', input_shape=train_data.shape[1:]))\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation = 'relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512, (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7), metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "batch_size = 32\n",
    "print(val_data.shape)\n",
    "model.fit(train_data,train_target,epochs = epochs, batch_size = batch_size,validation_data = (val_data, val_target), shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at /home/alexander/Documents/Cursos/RN/Tareas/Projeto2/saved_models/facesv1.h5 \n",
      "582/582 [==============================] - 4s 6ms/step\n",
      "Test loss: 1.3722925921486007\n",
      "Test accuracy: 0.6975945015133861\n",
      "1000/1000 [==============================] - 6s 6ms/step\n",
      "Val loss: 7.136528518676758\n",
      "Val accuracy: 0.223\n"
     ]
    }
   ],
   "source": [
    "model_name        = 'facesv1.h5'\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# train_data, train_target, test_data, test_target, val_data, val_target = load_data(categories)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(test_data, test_target, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "scores = model.evaluate(val_data, val_target, verbose=1)\n",
    "print('Val loss:', scores[0])\n",
    "print('Val accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=train_data.shape[1:], kernel_regularizer=l2(0.01)))\n",
    "model.add(Conv2D(64, (3, 3), padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))    \n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))    \n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))    \n",
    "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))    \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "learning_rate = 0.001\n",
    "adam = Adam(lr = learning_rate)\n",
    "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 48, 48, 3)\n",
      "Train on 2328 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "2328/2328 [==============================] - 76s 33ms/step - loss: 3.5901 - acc: 0.1641 - val_loss: 2.0292 - val_acc: 0.1790\n",
      "Epoch 2/100\n",
      "2328/2328 [==============================] - 70s 30ms/step - loss: 2.3319 - acc: 0.1791 - val_loss: 1.9167 - val_acc: 0.4530\n",
      "Epoch 3/100\n",
      "2328/2328 [==============================] - 51s 22ms/step - loss: 2.1305 - acc: 0.1967 - val_loss: 1.9188 - val_acc: 0.4650\n",
      "Epoch 4/100\n",
      "2328/2328 [==============================] - 51s 22ms/step - loss: 2.0459 - acc: 0.2075 - val_loss: 1.8994 - val_acc: 0.4650\n",
      "Epoch 5/100\n",
      "2328/2328 [==============================] - 58s 25ms/step - loss: 2.0218 - acc: 0.2178 - val_loss: 1.8997 - val_acc: 0.4650\n",
      "Epoch 6/100\n",
      "2328/2328 [==============================] - 73s 31ms/step - loss: 1.9940 - acc: 0.2195 - val_loss: 1.8740 - val_acc: 0.4650\n",
      "Epoch 7/100\n",
      "2328/2328 [==============================] - 69s 29ms/step - loss: 1.9594 - acc: 0.2341 - val_loss: 1.8589 - val_acc: 0.4650\n",
      "Epoch 8/100\n",
      "2328/2328 [==============================] - 59s 25ms/step - loss: 1.9486 - acc: 0.2431 - val_loss: 1.8398 - val_acc: 0.4650\n",
      "Epoch 9/100\n",
      "2328/2328 [==============================] - 63s 27ms/step - loss: 1.9290 - acc: 0.2470 - val_loss: 1.8288 - val_acc: 0.4650\n",
      "Epoch 10/100\n",
      "2328/2328 [==============================] - 75s 32ms/step - loss: 1.9319 - acc: 0.2427 - val_loss: 1.8217 - val_acc: 0.4650\n",
      "Epoch 11/100\n",
      "2328/2328 [==============================] - 70s 30ms/step - loss: 1.9239 - acc: 0.2423 - val_loss: 1.8231 - val_acc: 0.4650\n",
      "Epoch 12/100\n",
      "2328/2328 [==============================] - 66s 28ms/step - loss: 1.9264 - acc: 0.2483 - val_loss: 1.8232 - val_acc: 0.4650\n",
      "Epoch 13/100\n",
      "2328/2328 [==============================] - 61s 26ms/step - loss: 1.9221 - acc: 0.2483 - val_loss: 1.8156 - val_acc: 0.4650\n",
      "Epoch 14/100\n",
      "2328/2328 [==============================] - 56s 24ms/step - loss: 1.9071 - acc: 0.2509 - val_loss: 1.8101 - val_acc: 0.4650\n",
      "Epoch 15/100\n",
      "2328/2328 [==============================] - 56s 24ms/step - loss: 1.9173 - acc: 0.2487 - val_loss: 1.8018 - val_acc: 0.4650\n",
      "Epoch 16/100\n",
      "2328/2328 [==============================] - 59s 26ms/step - loss: 1.9053 - acc: 0.2487 - val_loss: 1.7979 - val_acc: 0.4650\n",
      "Epoch 17/100\n",
      "2328/2328 [==============================] - 67s 29ms/step - loss: 1.9012 - acc: 0.2521 - val_loss: 1.7896 - val_acc: 0.4650\n",
      "Epoch 18/100\n",
      "2328/2328 [==============================] - 74s 32ms/step - loss: 1.8991 - acc: 0.2569 - val_loss: 1.7879 - val_acc: 0.4650\n",
      "Epoch 19/100\n",
      "2328/2328 [==============================] - 68s 29ms/step - loss: 1.9051 - acc: 0.2517 - val_loss: 1.7899 - val_acc: 0.4650\n",
      "Epoch 20/100\n",
      "2328/2328 [==============================] - 65s 28ms/step - loss: 1.8964 - acc: 0.2552 - val_loss: 1.7861 - val_acc: 0.4650\n",
      "Epoch 21/100\n",
      "2328/2328 [==============================] - 62s 27ms/step - loss: 1.8940 - acc: 0.2530 - val_loss: 1.7798 - val_acc: 0.4650\n",
      "Epoch 22/100\n",
      "2328/2328 [==============================] - 59s 25ms/step - loss: 1.8941 - acc: 0.2526 - val_loss: 1.7774 - val_acc: 0.4650\n",
      "Epoch 23/100\n",
      "2328/2328 [==============================] - 58s 25ms/step - loss: 1.8947 - acc: 0.2569 - val_loss: 1.7769 - val_acc: 0.4650\n",
      "Epoch 24/100\n",
      "2328/2328 [==============================] - 60s 26ms/step - loss: 1.8915 - acc: 0.2564 - val_loss: 1.7709 - val_acc: 0.4650\n",
      "Epoch 25/100\n",
      "2328/2328 [==============================] - 51s 22ms/step - loss: 1.8905 - acc: 0.2539 - val_loss: 1.7694 - val_acc: 0.4650\n",
      "Epoch 26/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8891 - acc: 0.2543 - val_loss: 1.7599 - val_acc: 0.4650\n",
      "Epoch 27/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8890 - acc: 0.2556 - val_loss: 1.7610 - val_acc: 0.4650\n",
      "Epoch 28/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8834 - acc: 0.2556 - val_loss: 1.7532 - val_acc: 0.4650\n",
      "Epoch 29/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8791 - acc: 0.2573 - val_loss: 1.7570 - val_acc: 0.4650\n",
      "Epoch 30/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8810 - acc: 0.2547 - val_loss: 1.7549 - val_acc: 0.4650\n",
      "Epoch 31/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8804 - acc: 0.2560 - val_loss: 1.7555 - val_acc: 0.4650\n",
      "Epoch 32/100\n",
      "2328/2328 [==============================] - 48s 21ms/step - loss: 1.8792 - acc: 0.2564 - val_loss: 1.7568 - val_acc: 0.4650\n",
      "Epoch 33/100\n",
      "2328/2328 [==============================] - 48s 21ms/step - loss: 1.8824 - acc: 0.2526 - val_loss: 1.7515 - val_acc: 0.4650\n",
      "Epoch 34/100\n",
      "2328/2328 [==============================] - 48s 21ms/step - loss: 1.8781 - acc: 0.2560 - val_loss: 1.7496 - val_acc: 0.4650\n",
      "Epoch 35/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8778 - acc: 0.2556 - val_loss: 1.7513 - val_acc: 0.4650\n",
      "Epoch 36/100\n",
      "2328/2328 [==============================] - 52s 22ms/step - loss: 1.8741 - acc: 0.2569 - val_loss: 1.7498 - val_acc: 0.4650\n",
      "Epoch 37/100\n",
      "2328/2328 [==============================] - 51s 22ms/step - loss: 1.8739 - acc: 0.2530 - val_loss: 1.7503 - val_acc: 0.4650\n",
      "Epoch 38/100\n",
      "2328/2328 [==============================] - 51s 22ms/step - loss: 1.8689 - acc: 0.2582 - val_loss: 1.7464 - val_acc: 0.4650\n",
      "Epoch 39/100\n",
      "2328/2328 [==============================] - 51s 22ms/step - loss: 1.8745 - acc: 0.2556 - val_loss: 1.7507 - val_acc: 0.4650\n",
      "Epoch 40/100\n",
      "2328/2328 [==============================] - 51s 22ms/step - loss: 1.8702 - acc: 0.2547 - val_loss: 1.7473 - val_acc: 0.4650\n",
      "Epoch 41/100\n",
      "2328/2328 [==============================] - 51s 22ms/step - loss: 1.8713 - acc: 0.2569 - val_loss: 1.7440 - val_acc: 0.4650\n",
      "Epoch 42/100\n",
      "2328/2328 [==============================] - 50s 22ms/step - loss: 1.8711 - acc: 0.2547 - val_loss: 1.7483 - val_acc: 0.4650\n",
      "Epoch 43/100\n",
      "2328/2328 [==============================] - 50s 22ms/step - loss: 1.8669 - acc: 0.2564 - val_loss: 1.7408 - val_acc: 0.4650\n",
      "Epoch 44/100\n",
      "2328/2328 [==============================] - 50s 21ms/step - loss: 1.8670 - acc: 0.2564 - val_loss: 1.7441 - val_acc: 0.4650\n",
      "Epoch 45/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8707 - acc: 0.2564 - val_loss: 1.7422 - val_acc: 0.4650\n",
      "Epoch 46/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8645 - acc: 0.2564 - val_loss: 1.7415 - val_acc: 0.4650\n",
      "Epoch 47/100\n",
      "2328/2328 [==============================] - 50s 21ms/step - loss: 1.8643 - acc: 0.2539 - val_loss: 1.7385 - val_acc: 0.4650\n",
      "Epoch 48/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8612 - acc: 0.2569 - val_loss: 1.7460 - val_acc: 0.4650\n",
      "Epoch 49/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8648 - acc: 0.2526 - val_loss: 1.7384 - val_acc: 0.4650\n",
      "Epoch 50/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8572 - acc: 0.2556 - val_loss: 1.7424 - val_acc: 0.4650\n",
      "Epoch 51/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8559 - acc: 0.2560 - val_loss: 1.7520 - val_acc: 0.4650\n",
      "Epoch 52/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8626 - acc: 0.2573 - val_loss: 1.7391 - val_acc: 0.4650\n",
      "Epoch 53/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8591 - acc: 0.2547 - val_loss: 1.7395 - val_acc: 0.4650\n",
      "Epoch 54/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8591 - acc: 0.2564 - val_loss: 1.7393 - val_acc: 0.4650\n",
      "Epoch 55/100\n",
      "2328/2328 [==============================] - 48s 21ms/step - loss: 1.8565 - acc: 0.2552 - val_loss: 1.7355 - val_acc: 0.4650\n",
      "Epoch 56/100\n",
      "2328/2328 [==============================] - 48s 21ms/step - loss: 1.8564 - acc: 0.2547 - val_loss: 1.7215 - val_acc: 0.4650\n",
      "Epoch 57/100\n",
      "2328/2328 [==============================] - 48s 20ms/step - loss: 1.8624 - acc: 0.2586 - val_loss: 1.7390 - val_acc: 0.4650\n",
      "Epoch 58/100\n",
      "2328/2328 [==============================] - 48s 21ms/step - loss: 1.8582 - acc: 0.2603 - val_loss: 1.7377 - val_acc: 0.4650\n",
      "Epoch 59/100\n",
      "2328/2328 [==============================] - 52s 22ms/step - loss: 1.8563 - acc: 0.2552 - val_loss: 1.7375 - val_acc: 0.4650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "2328/2328 [==============================] - 51s 22ms/step - loss: 1.8550 - acc: 0.2573 - val_loss: 1.7418 - val_acc: 0.4580\n",
      "Epoch 61/100\n",
      "2328/2328 [==============================] - 51s 22ms/step - loss: 1.8527 - acc: 0.2569 - val_loss: 1.7337 - val_acc: 0.4650\n",
      "Epoch 62/100\n",
      "2328/2328 [==============================] - 51s 22ms/step - loss: 1.8538 - acc: 0.2573 - val_loss: 1.7319 - val_acc: 0.4660\n",
      "Epoch 63/100\n",
      "2328/2328 [==============================] - 51s 22ms/step - loss: 1.8493 - acc: 0.2620 - val_loss: 1.7303 - val_acc: 0.4650\n",
      "Epoch 64/100\n",
      "2328/2328 [==============================] - 50s 22ms/step - loss: 1.8554 - acc: 0.2543 - val_loss: 1.7287 - val_acc: 0.4650\n",
      "Epoch 65/100\n",
      "2328/2328 [==============================] - 50s 22ms/step - loss: 1.8529 - acc: 0.2590 - val_loss: 1.7112 - val_acc: 0.4650\n",
      "Epoch 66/100\n",
      "2328/2328 [==============================] - 50s 21ms/step - loss: 1.8556 - acc: 0.2552 - val_loss: 1.7292 - val_acc: 0.4650\n",
      "Epoch 67/100\n",
      "2328/2328 [==============================] - 50s 21ms/step - loss: 1.8514 - acc: 0.2569 - val_loss: 1.7295 - val_acc: 0.4650\n",
      "Epoch 68/100\n",
      "2328/2328 [==============================] - 50s 21ms/step - loss: 1.8479 - acc: 0.2582 - val_loss: 1.7218 - val_acc: 0.4650\n",
      "Epoch 69/100\n",
      "2328/2328 [==============================] - 50s 21ms/step - loss: 1.8556 - acc: 0.2552 - val_loss: 1.7291 - val_acc: 0.4650\n",
      "Epoch 70/100\n",
      "2328/2328 [==============================] - 50s 21ms/step - loss: 1.8484 - acc: 0.2590 - val_loss: 1.7277 - val_acc: 0.4650\n",
      "Epoch 71/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8464 - acc: 0.2560 - val_loss: 1.7276 - val_acc: 0.4650\n",
      "Epoch 72/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8514 - acc: 0.2607 - val_loss: 1.7294 - val_acc: 0.4650\n",
      "Epoch 73/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8549 - acc: 0.2556 - val_loss: 1.7260 - val_acc: 0.4650\n",
      "Epoch 74/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8570 - acc: 0.2573 - val_loss: 1.7282 - val_acc: 0.4650\n",
      "Epoch 75/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8478 - acc: 0.2552 - val_loss: 1.7279 - val_acc: 0.4650\n",
      "Epoch 76/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8447 - acc: 0.2612 - val_loss: 1.7280 - val_acc: 0.4640\n",
      "Epoch 77/100\n",
      "2328/2328 [==============================] - 48s 21ms/step - loss: 1.8495 - acc: 0.2564 - val_loss: 1.7272 - val_acc: 0.4650\n",
      "Epoch 78/100\n",
      "2328/2328 [==============================] - 48s 21ms/step - loss: 1.8482 - acc: 0.2547 - val_loss: 1.7278 - val_acc: 0.4650\n",
      "Epoch 79/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8486 - acc: 0.2539 - val_loss: 1.7326 - val_acc: 0.4630\n",
      "Epoch 80/100\n",
      "2328/2328 [==============================] - 48s 21ms/step - loss: 1.8453 - acc: 0.2629 - val_loss: 1.7410 - val_acc: 0.4400\n",
      "Epoch 81/100\n",
      "2328/2328 [==============================] - 48s 21ms/step - loss: 1.8471 - acc: 0.2573 - val_loss: 1.7275 - val_acc: 0.4650\n",
      "Epoch 82/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8510 - acc: 0.2577 - val_loss: 1.7279 - val_acc: 0.4650\n",
      "Epoch 83/100\n",
      "2328/2328 [==============================] - 52s 22ms/step - loss: 1.8490 - acc: 0.2556 - val_loss: 1.7277 - val_acc: 0.4650\n",
      "Epoch 84/100\n",
      "2328/2328 [==============================] - 51s 22ms/step - loss: 1.8436 - acc: 0.2607 - val_loss: 1.7258 - val_acc: 0.4650\n",
      "Epoch 85/100\n",
      "2328/2328 [==============================] - 51s 22ms/step - loss: 1.8478 - acc: 0.2599 - val_loss: 1.7270 - val_acc: 0.4650\n",
      "Epoch 86/100\n",
      "2328/2328 [==============================] - 51s 22ms/step - loss: 1.8429 - acc: 0.2582 - val_loss: 1.7301 - val_acc: 0.4650\n",
      "Epoch 87/100\n",
      "2328/2328 [==============================] - 51s 22ms/step - loss: 1.8445 - acc: 0.2556 - val_loss: 1.7268 - val_acc: 0.4650\n",
      "Epoch 88/100\n",
      "2328/2328 [==============================] - 50s 22ms/step - loss: 1.8344 - acc: 0.2698 - val_loss: 1.7296 - val_acc: 0.4530\n",
      "Epoch 89/100\n",
      "2328/2328 [==============================] - 50s 22ms/step - loss: 1.8392 - acc: 0.2706 - val_loss: 1.7302 - val_acc: 0.4580\n",
      "Epoch 90/100\n",
      "2328/2328 [==============================] - 50s 21ms/step - loss: 1.8383 - acc: 0.2723 - val_loss: 1.7342 - val_acc: 0.4470\n",
      "Epoch 91/100\n",
      "2328/2328 [==============================] - 50s 21ms/step - loss: 1.8343 - acc: 0.2762 - val_loss: 1.7214 - val_acc: 0.4650\n",
      "Epoch 92/100\n",
      "2328/2328 [==============================] - 50s 21ms/step - loss: 1.8438 - acc: 0.2607 - val_loss: 1.7233 - val_acc: 0.4600\n",
      "Epoch 93/100\n",
      "2328/2328 [==============================] - 50s 21ms/step - loss: 1.8372 - acc: 0.2732 - val_loss: 1.7491 - val_acc: 0.4420\n",
      "Epoch 94/100\n",
      "2328/2328 [==============================] - 50s 21ms/step - loss: 1.8359 - acc: 0.2762 - val_loss: 1.7250 - val_acc: 0.4560\n",
      "Epoch 95/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8345 - acc: 0.2728 - val_loss: 1.7219 - val_acc: 0.4570\n",
      "Epoch 96/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8328 - acc: 0.2706 - val_loss: 1.7204 - val_acc: 0.4620\n",
      "Epoch 97/100\n",
      "2328/2328 [==============================] - 49s 21ms/step - loss: 1.8460 - acc: 0.2590 - val_loss: 1.7243 - val_acc: 0.4650\n",
      "Epoch 98/100\n",
      "2328/2328 [==============================] - 48s 21ms/step - loss: 1.8357 - acc: 0.2728 - val_loss: 1.7477 - val_acc: 0.4290\n",
      "Epoch 99/100\n",
      "2328/2328 [==============================] - 48s 21ms/step - loss: 1.8384 - acc: 0.2771 - val_loss: 1.7644 - val_acc: 0.4170\n",
      "Epoch 100/100\n",
      "2328/2328 [==============================] - 48s 21ms/step - loss: 1.8199 - acc: 0.2848 - val_loss: 1.7434 - val_acc: 0.4240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa5f4238990>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "print(val_data.shape)\n",
    "model.fit(train_data,train_target,epochs = epochs, batch_size = batch_size,validation_data = (val_data, val_target), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at /home/alexander/Documents/Cursos/RN/Tareas/Projeto2/saved_models/facesv2.h5 \n",
      "582/582 [==============================] - 4s 6ms/step\n",
      "Test loss: 1.8071630287825857\n",
      "Test accuracy: 0.2920962199824782\n",
      "1000/1000 [==============================] - 6s 6ms/step\n",
      "Val loss: 1.743383279800415\n",
      "Val accuracy: 0.424\n"
     ]
    }
   ],
   "source": [
    "model_name        = 'facesv2.h5'\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# train_data, train_target, test_data, test_target, val_data, val_target = load_data(categories)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(test_data, test_target, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "scores = model.evaluate(val_data, val_target, verbose=1)\n",
    "print('Val loss:', scores[0])\n",
    "print('Val accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1003 15:05:08.971750 19840 deprecation.py:323] From C:\\Users\\1312\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "73/73 [==============================] - 113s 2s/step - loss: 3.2465 - acc: 0.1727 - val_loss: 1.8979 - val_acc: 0.2509\n",
      "Epoch 2/30\n",
      "73/73 [==============================] - 106s 1s/step - loss: 2.3735 - acc: 0.1996 - val_loss: 1.9979 - val_acc: 0.1976\n",
      "Epoch 3/30\n",
      "73/73 [==============================] - 112s 2s/step - loss: 2.2985 - acc: 0.2021 - val_loss: 1.9815 - val_acc: 0.2199\n",
      "Epoch 4/30\n",
      "73/73 [==============================] - 107s 1s/step - loss: 2.0708 - acc: 0.2125 - val_loss: 1.8968 - val_acc: 0.2354\n",
      "Epoch 5/30\n",
      "73/73 [==============================] - 111s 2s/step - loss: 1.9698 - acc: 0.2125 - val_loss: 1.8810 - val_acc: 0.2526\n",
      "Epoch 6/30\n",
      "73/73 [==============================] - 110s 2s/step - loss: 1.9480 - acc: 0.2059 - val_loss: 1.8907 - val_acc: 0.2560\n",
      "Epoch 7/30\n",
      "49/73 [===================>..........] - ETA: 33s - loss: 1.9416 - acc: 0.2117"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-4d6ca32279c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m# Fit the model on the batches generated by datagen.flow().\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m# Save model and weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "datagen.fit(train_data)\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "generator = datagen.flow(train_data, train_target,batch_size=batch_size)\n",
    "model.fit_generator(generator, epochs=epochs,validation_data=(test_data, test_target),workers=4, steps_per_epoch = len(generator))\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(test_data, test_target, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 48, 48, 3)\n",
      "Train on 2328 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "2328/2328 [==============================] - 288s 124ms/step - loss: 2.3914 - acc: 0.1654 - val_loss: 1.9407 - val_acc: 0.3610\n",
      "Epoch 2/30\n",
      " 832/2328 [=========>....................] - ETA: 2:26 - loss: 2.3327 - acc: 0.1755"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-0e247b212676>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "print(val_data.shape)\n",
    "model.fit(train_data,train_target,epochs = epochs, batch_size = batch_size,validation_data = (val_data, val_target), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

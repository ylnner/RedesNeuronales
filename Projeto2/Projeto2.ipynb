{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processCategory(category):\n",
    "    y = []\n",
    "    if category == 'angry':\n",
    "        y = [1, 0, 0, 0, 0, 0, 0]        \n",
    "    elif category == 'disgust':\n",
    "        y = [0, 1, 0, 0, 0, 0, 0]\n",
    "    elif category == 'fear':\n",
    "        y = [0, 0, 1, 0, 0, 0, 0]\n",
    "    elif category == 'happy':\n",
    "        y = [0, 0, 0, 1, 0, 0, 0]\n",
    "    elif category == 'neutral':\n",
    "        y = [0, 0, 0, 0, 1, 0, 0]\n",
    "    elif category == 'sad':\n",
    "        y = [0, 0, 0, 0, 0, 1, 0]\n",
    "    elif category == 'surprise':\n",
    "        y = [0, 0, 0, 0, 0, 0, 1]\n",
    "    \n",
    "    return y\n",
    "\n",
    "def load_data(categories):\n",
    "    # Training and Testing\n",
    "    data             = []\n",
    "    target           = []\n",
    "    size_image       = 32\n",
    "    img_dir          = 'train'    \n",
    "    \n",
    "    for idx, category in enumerate(categories):\n",
    "        img_dir_aux = img_dir + '/'+ category\n",
    "        data_path   = os.path.join(img_dir_aux, '*g')\n",
    "        files       = glob.glob(data_path)\n",
    "        for f1 in files:\n",
    "            img        = cv2.imread(f1)\n",
    "            img_resize = cv2.resize(img, (size_image, size_image), interpolation = cv2.INTER_AREA)\n",
    "            data.append(img_resize)\n",
    "            target.append(idx)\n",
    "\n",
    "    target     = keras.utils.to_categorical(target, len(categories))    \n",
    "    data       = np.array(data)\n",
    "    target     = np.array(target)\n",
    "    stratSplit = StratifiedShuffleSplit(n_splits=1, test_size=0.8, random_state=42)\n",
    "    for test_idx, train_idx in stratSplit.split(data, target):        \n",
    "        train_data   = data[train_idx]\n",
    "        train_target = target[train_idx]                        \n",
    "        test_data    = data[test_idx]\n",
    "        test_target  = target[test_idx]\n",
    "        \n",
    "    # Validation\n",
    "    val_data   = []\n",
    "    val_target = []\n",
    "    img_dir    = 'val'\n",
    "    for idx, category in enumerate(categories):        \n",
    "        img_dir_aux = img_dir + '/'+ category\n",
    "        data_path   = os.path.join(img_dir_aux, '*g')\n",
    "        files       = glob.glob(data_path)        \n",
    "        for f1 in files:\n",
    "            img        = cv2.imread(f1)\n",
    "            img_resize = cv2.resize(img, (size_image, size_image), interpolation = cv2.INTER_AREA)\n",
    "            val_data.append(img_resize)\n",
    "            val_target.append(idx)\n",
    "    \n",
    "    val_target   = keras.utils.to_categorical(val_target, len(categories))                \n",
    "    val_data     = np.array(val_data)\n",
    "    val_target   = np.array(val_target)\n",
    "    \n",
    "    np.random.shuffle(val_data)\n",
    "    np.random.shuffle(val_target)    \n",
    "    \n",
    "    return train_data, train_target, test_data, test_target, val_data, val_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "categories  = ['angry','disgust','fear','happy','neutral','sad','surprise']\n",
    "train_data, train_target, test_data, test_target, val_data, val_target = load_data(categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size        = 32\n",
    "num_classes       = 7\n",
    "data_augmentation = True\n",
    "num_predictions   = 20\n",
    "save_dir          = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name        = 'faces.h5'\n",
    "categories  = ['angry','disgust','fear','happy','neutral','sad','surprise']\n",
    "train_data, train_target, test_data, test_target, val_data, val_target = load_data(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs            = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "73/73 [==============================] - 8s 109ms/step - loss: 13.8437 - acc: 0.1396 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 13.8827 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 13.8780 - acc: 0.1390 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 13.8803 - acc: 0.1388 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 13.8780 - acc: 0.1390 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 13.8825 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 13.8871 - acc: 0.1384 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 7s 98ms/step - loss: 13.8848 - acc: 0.1386 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 13.8825 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 13.8825 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 13.8803 - acc: 0.1388 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 13.8825 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 13.8871 - acc: 0.1384 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 13.8825 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 13.8780 - acc: 0.1390 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 13.8825 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 13.8848 - acc: 0.1386 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 7s 99ms/step - loss: 13.8825 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 13.8803 - acc: 0.1388 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 7s 101ms/step - loss: 13.8825 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 13.8848 - acc: 0.1386 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 7s 99ms/step - loss: 13.8825 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 7s 98ms/step - loss: 13.8825 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 13.8825 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 13.8871 - acc: 0.1384 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 13.8803 - acc: 0.1388 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 13.8848 - acc: 0.1386 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 13.8757 - acc: 0.1391 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 7s 98ms/step - loss: 13.8848 - acc: 0.1386 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 13.8871 - acc: 0.1384 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 13.8871 - acc: 0.1384 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 13.8780 - acc: 0.1390 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 13.8825 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 13.8848 - acc: 0.1386 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 13.8825 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 13.8757 - acc: 0.1391 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 13.8848 - acc: 0.1386 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 13.8757 - acc: 0.1391 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 13.8757 - acc: 0.1391 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 13.8871 - acc: 0.1384 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 13.8825 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 13.8825 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 13.8871 - acc: 0.1384 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 13.8825 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 13.8825 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 13.8757 - acc: 0.1391 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 13.8825 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 13.8825 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 13.8757 - acc: 0.1391 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 13.8825 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 13.8803 - acc: 0.1388 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 13.8803 - acc: 0.1388 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 13.8848 - acc: 0.1386 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 13.8803 - acc: 0.1388 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 13.8848 - acc: 0.1386 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 13.8689 - acc: 0.1395 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 13.8893 - acc: 0.1383 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 13.8825 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 13.8780 - acc: 0.1390 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 13.8735 - acc: 0.1393 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 13.8871 - acc: 0.1384 - val_loss: 13.8749 - val_acc: 0.1392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 13.8803 - acc: 0.1388 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 13.8825 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 13.8803 - acc: 0.1388 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 13.8825 - acc: 0.1387 - val_loss: 13.8749 - val_acc: 0.1392\n",
      "Epoch 66/100\n",
      "72/73 [============================>.] - ETA: 0s - loss: 13.9005 - acc: 0.1376"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-d80142681b1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Fit the model on the batches generated by datagen.flow().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Save model and weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    240\u001b[0m                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_sample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                             verbose=0)\n\u001b[0m\u001b[1;32m    243\u001b[0m                     \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                     \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1111\u001b[0m                                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                                          \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                                          steps=steps)\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m     def predict(self, x,\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=train_data.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "datagen.fit(train_data)\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "generator = datagen.flow(train_data, train_target,batch_size=batch_size)\n",
    "model.fit_generator(generator, epochs=epochs,validation_data=(test_data, test_target),workers=4, steps_per_epoch = len(generator))\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(test_data, test_target, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
